[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "At its core, data.table provides an enhanced version of data.frames that are faster, more memory efficient and can be manipulated using a more concise syntax. It also provides a whole set of extra functions for reading from and writing to tabular files, reshaping data between long and wide formats, joining data sets and much more.\ndata.table mascot is a sea lion, which barks “R R R”\nTake a quick look at it functionalities:\n\nIt is a great time to join the data.table community! In 2023-2025, National Science Foundation has provided funds to support expanding the ecosystem of users and contributors around data.table. You can start checking:\n\nThe Raft rdatatable-community.github.io/The-Raft, the data.table blog. Sea lions often float together on the ocean’s surface in groups called “rafts”.\nThe GitHub repo with 900+ open issues, 100+ open PRs. If you have any time/interest, we could use your help!"
  },
  {
    "objectID": "about.html#data.table",
    "href": "about.html#data.table",
    "title": "About",
    "section": "",
    "text": "At its core, data.table provides an enhanced version of data.frames that are faster, more memory efficient and can be manipulated using a more concise syntax. It also provides a whole set of extra functions for reading from and writing to tabular files, reshaping data between long and wide formats, joining data sets and much more.\ndata.table mascot is a sea lion, which barks “R R R”\nTake a quick look at it functionalities:\n\nIt is a great time to join the data.table community! In 2023-2025, National Science Foundation has provided funds to support expanding the ecosystem of users and contributors around data.table. You can start checking:\n\nThe Raft rdatatable-community.github.io/The-Raft, the data.table blog. Sea lions often float together on the ocean’s surface in groups called “rafts”.\nThe GitHub repo with 900+ open issues, 100+ open PRs. If you have any time/interest, we could use your help!"
  },
  {
    "objectID": "about.html#the-tutorial",
    "href": "about.html#the-tutorial",
    "title": "About",
    "section": "…the tutorial",
    "text": "…the tutorial\nThis tutorial was developed to be presented at useR! 2024 thanks to a travel award given to Pao. The original slides for that version of the tutorial are available here."
  },
  {
    "objectID": "about.html#us",
    "href": "about.html#us",
    "title": "About",
    "section": "…us",
    "text": "…us\nPao Corrales\n Pao has a PhD from the University of Buenos Aires. She studied atmospheric sciences applying data assimilation techniques to improve short-term forecasts of severe events in Argentina. She is also a Trainer and instructor for The Carpentries and a professor at the Data Sciences degree and postgraduate courses at Guillermo Brown University. She is an active R user and developer and contributes to many communities of practice, such as R-Ladies and rOpenSci.\nMore information about Pao: paobcorrales.github.io\nElio Campitelli\n Elio has a PhD from the University of Buenos Aires in atmospheric sciences and is an active R package developer. They apply open science principles with a strong emphasis on reproducibility by publicly making all the code and data available. They’s a founding member of the R User Group in Buenos Aires and part of LatinR and rOpenSci communities. They maintain several open-source R packages (e.g., ggnewscale; metR) and contribute to other packages, such as data.table and ggplot2.\nMore informations about Elio: eliocamp.github.io"
  },
  {
    "objectID": "sandbox.html",
    "href": "sandbox.html",
    "title": "Sandbox",
    "section": "",
    "text": "This is a sandbox, a code chunk to run R code using webR. data.table and ggplot2 are already loaded along with the Rolling Stone data set. Everything is ready to run the tutorial’s examples and exercises.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page."
  },
  {
    "objectID": "slides.html#section",
    "href": "slides.html#section",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Who are we?\nPao, Elio"
  },
  {
    "objectID": "slides.html#section-1",
    "href": "slides.html#section-1",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Who are you?\nShare your name and what’s your favourite ice-cream flavour."
  },
  {
    "objectID": "slides.html#housekeeping",
    "href": "slides.html#housekeeping",
    "title": "Efficient data analysis with data.table",
    "section": "Housekeeping",
    "text": "Housekeeping\nYou will need:\n\nR\ndata.table\n\ninstall.packages(\"data.table\")\n\nggplot2 or any other visualisation package (optional)"
  },
  {
    "objectID": "slides.html#what-is-data.table",
    "href": "slides.html#what-is-data.table",
    "title": "Efficient data analysis with data.table",
    "section": "What is data.table?",
    "text": "What is data.table?\nAt its core, data.table provides an enhanced version of data.frames that are faster, more memory efficient and can be manipulated using a more concise syntax.\nIt also provides a whole set of extra functions for reading from and writing to tabular files, reshaping data between long and wide formats, joining datasets and much more."
  },
  {
    "objectID": "slides.html#why-data.table",
    "href": "slides.html#why-data.table",
    "title": "Efficient data analysis with data.table",
    "section": "Why data.table?",
    "text": "Why data.table?\n\nFast and efficient\nDoes not have dependencies\nSyntax is very concise\nEnsures backwards compatibility"
  },
  {
    "objectID": "slides.html#follow-along",
    "href": "slides.html#follow-along",
    "title": "Efficient data analysis with data.table",
    "section": "Follow along",
    "text": "Follow along\nIf you can, try the code we will show you on the screen.\nIf you’re stuck or need help, tell us in the chat.\nMaterials\nhttps://paocorrales.github.io/intro-datatable/"
  },
  {
    "objectID": "slides.html#the-syntax",
    "href": "slides.html#the-syntax",
    "title": "Efficient data analysis with data.table",
    "section": "The syntax",
    "text": "The syntax\nThe general data.table syntax looks like this:\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining operations, the j argument can summarise and transform, and the by argument defines the groups to which to apply these operations.\nYou can read the syntax as “In these rows, do this, grouped by that”.\nIt is very concise but easy to read (sometimes)."
  },
  {
    "objectID": "slides.html#section-2",
    "href": "slides.html#section-2",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Exercises"
  },
  {
    "objectID": "slides.html#section-3",
    "href": "slides.html#section-3",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "How to contribute"
  },
  {
    "objectID": "slides.html#it-is-a-great-time-to-join-the-data.table-community",
    "href": "slides.html#it-is-a-great-time-to-join-the-data.table-community",
    "title": "Efficient data analysis with data.table",
    "section": "It is a great time to join the data.table community!",
    "text": "It is a great time to join the data.table community!\nIn 2023-2025, National Science Foundation has provided funds to support expanding the ecosystem of users and contributors around data.table.\n\ndata.table on Mastodon: @r_data_table@fosstodon.org\nThe Raft rdatatable-community.github.io/The-Raft, the data.table blog.\nThe GitHub repo with 900+ open issues, 100+ open PRs. If you have any time/interest, we could use your help!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "data.table is one of the most efficient open-source in-memory data manipulation packages available today. It can summarise, compute new variables, re-arrange tables and perform group-wise operations quickly, and memory efficiently thanks to its highly optimised C code. It also provides fast alternatives to base R functions for reading and writing files.\nThis three-hour tutorial will introduce participants to data.table’s basics. Through live coding sessions and hands-on exercises, we will learn how to use data.table as part of a data analysis pipeline; from reading data into memory to writing the results back, including exploration, data manipulation and joins. The tutorial will also lay the foundations for learning more advanced features, such as special symbols and combined operations.\n\n\n All materials in this course are under the license Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "data.table is one of the most efficient open-source in-memory data manipulation packages available today. It can summarise, compute new variables, re-arrange tables and perform group-wise operations quickly, and memory efficiently thanks to its highly optimised C code. It also provides fast alternatives to base R functions for reading and writing files.\nThis three-hour tutorial will introduce participants to data.table’s basics. Through live coding sessions and hands-on exercises, we will learn how to use data.table as part of a data analysis pipeline; from reading data into memory to writing the results back, including exploration, data manipulation and joins. The tutorial will also lay the foundations for learning more advanced features, such as special symbols and combined operations.\n\n\n All materials in this course are under the license Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "slides_useR.html#section",
    "href": "slides_useR.html#section",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Who are we?\nPao, Elio, Kelly"
  },
  {
    "objectID": "slides_useR.html#section-1",
    "href": "slides_useR.html#section-1",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Who are you?\nIntroduce yourself to your neighbours 👋\nShare your name and how many hours it took you to arrive to Salzburg"
  },
  {
    "objectID": "slides_useR.html#housekeeping",
    "href": "slides_useR.html#housekeeping",
    "title": "Efficient data analysis with data.table",
    "section": "Housekeeping",
    "text": "Housekeeping\nYou will need:\n\nR\ndata.table\n\ninstall.packages(\"data.table\")\n\nggplot2 or any other visualisation package (optional)\n\n\n\n\n\nWi-Fi network name\nuserr2024\n\n\n\n\nsalzburg\nTODO-ADD-LATER"
  },
  {
    "objectID": "slides_useR.html#what-is-data.table",
    "href": "slides_useR.html#what-is-data.table",
    "title": "Efficient data analysis with data.table",
    "section": "What is data.table?",
    "text": "What is data.table?\nAt its core, data.table provides an enhanced version of data.frames that are faster, more memory efficient and can be manipulated using a more concise syntax.\nIt also provides a whole set of extra functions for reading from and writing to tabular files, reshaping data between long and wide formats, joining datasets and much more."
  },
  {
    "objectID": "slides_useR.html#why-data.table",
    "href": "slides_useR.html#why-data.table",
    "title": "Efficient data analysis with data.table",
    "section": "Why data.table?",
    "text": "Why data.table?\n\nFast and efficient\nDoes not have dependencies\nSyntax is very concise\nEnsures backwards compatibility"
  },
  {
    "objectID": "slides_useR.html#follow-along",
    "href": "slides_useR.html#follow-along",
    "title": "Efficient data analysis with data.table",
    "section": "Follow along",
    "text": "Follow along\nIf you can, try the code we will show you on the screen.\nFor the exercises, work in teams and use the sticky notes!\n\n🟪 “I’m stuck and need help!”\n\n\n🟩 “I finished the exercise”\n\n\nMaterials\nhttps://bit.ly/datatable-user2024"
  },
  {
    "objectID": "slides_useR.html#the-syntax",
    "href": "slides_useR.html#the-syntax",
    "title": "Efficient data analysis with data.table",
    "section": "The syntax",
    "text": "The syntax\nThe general data.table syntax looks like this:\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining operations, the j argument can summarise and transform, and the by argument defines the groups to which to apply these operations.\nYou can read the syntax as “In these rows, do this, grouped by that”.\nIt is very concise but easy to read (sometimes)."
  },
  {
    "objectID": "slides_useR.html#section-4",
    "href": "slides_useR.html#section-4",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "Exercises"
  },
  {
    "objectID": "slides_useR.html#section-5",
    "href": "slides_useR.html#section-5",
    "title": "Efficient data analysis with data.table",
    "section": "",
    "text": "How to contribute"
  },
  {
    "objectID": "slides_useR.html#it-is-a-great-time-to-join-the-data.table-community",
    "href": "slides_useR.html#it-is-a-great-time-to-join-the-data.table-community",
    "title": "Efficient data analysis with data.table",
    "section": "It is a great time to join the data.table community!",
    "text": "It is a great time to join the data.table community!\nIn 2023-2025, National Science Foundation has provided funds to support expanding the ecosystem of users and contributors around data.table.\n\ndata.table on Mastodon: @r_data_table@fosstodon.org\nThe Raft rdatatable-community.github.io/The-Raft, the data.table blog.\nThe GitHub repo with 900+ open issues, 100+ open PRs. If you have any time/interest, we could use your help!"
  },
  {
    "objectID": "material.html#what-data.table",
    "href": "material.html#what-data.table",
    "title": "Introduction to data.table",
    "section": "What data.table?",
    "text": "What data.table?\nAt its core, data.table provides an enhanced version of data.frames that are faster, more memory efficient and can be manipulated using a more concise syntax. It also provides a whole set of extra functions for reading from and writing to tabular files, reshaping data between long and wide formats, joining datasets and much more."
  },
  {
    "objectID": "material.html#why-data.table",
    "href": "material.html#why-data.table",
    "title": "Introduction to data.table",
    "section": "Why data.table?",
    "text": "Why data.table?\n\nFast and efficient\nDoes not have dependencies\nSyntax is very concise\nEnsures backwards compatibility"
  },
  {
    "objectID": "material.html#reference-semantics",
    "href": "material.html#reference-semantics",
    "title": "Introduction to data.table",
    "section": "Reference semantics",
    "text": "Reference semantics\nMost R functions and methods uses copy-on-modify. This means that modifying an object almost always creates a new copy of the object, while the original one is kept unmodified. For example this code\nmy_data |&gt; \n  mutate(new_column = old_column*2)\nreturns a new tibble that is a copy of my_data with a new column but it doesn’t modify my_data.\ndata.table uses modify-in-place, which means that objects are not copied whene modified. This code\nmy_data[, new_column := old_column*2]\ndoesn’t create a new copy of my_data but it rather modifies my_data directly. This is similar to the base R code:\nmy_data$new_column &lt;- data$new_column\nModify-in-place is one of the features that makes data.table so efficient, but it can also make code harder to think about and lead to surprising results (especially if a data.table is modified inside a function).\nFunctions that modify a data.table in place start with “set”, like setcolorder() (reorders columns) or setnames() (renames columns)."
  },
  {
    "objectID": "material.html#reading-data-with-data.table",
    "href": "material.html#reading-data-with-data.table",
    "title": "Introduction to data.table",
    "section": "Reading data with data.table",
    "text": "Reading data with data.table\nThe first step of most data analyses is to read data in memory. We can use the data.table::fread() function (the f is for fast) to read regular delimited files such as csv files. This function not only is fast, but it automatically detects the delimiter and guesses the class of each column and the number of rows in the file.\n\nlibrary(data.table)\n\nrolling_stone &lt;- fread('data/rolling_stone.csv')\nIt is also possible to read data from a URL.\n\nrolling_stone &lt;- fread('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-05-07/rolling_stone.csv')\n\nfread() will return a data.table object. If you read a dataset as a data.frame or tibble and want to create it as a But sometimes you’ll have a data.frame or a tibble that you loaded into R using other methods. You can convert them to data.table either with the as.data.table() or setDT() functions. The difference is that as.data.table() returns a copy of the data as a data.table and setDT() changes the data in place (as denoted by the “set” prefix).\n\nsetDT(rolling_stone)\n\n\nThe Rolling Stone data\nThe data we’ll use comes from the TidyTuesday project, includes album rankings from Rolling Stone magazine. It has 21 variables and 691 observations, not a big task for data.table but it will help us to explore some of the functionalities.\n\nstr(rolling_stone)\n\nClasses 'data.table' and 'data.frame':  691 obs. of  21 variables:\n $ sort_name               : chr  \"Sinatra, Frank\" \"Diddley, Bo\" \"Presley, Elvis\" \"Sinatra, Frank\" ...\n $ clean_name              : chr  \"Frank Sinatra\" \"Bo Diddley\" \"Elvis Presley\" \"Frank Sinatra\" ...\n $ album                   : chr  \"In the Wee Small Hours\" \"Bo Diddley / Go Bo Diddley\" \"Elvis Presley\" \"Songs for Swingin' Lovers!\" ...\n $ rank_2003               : int  100 214 55 306 50 NA NA 421 NA 12 ...\n $ rank_2012               : int  101 216 56 308 50 NA 451 420 NA 12 ...\n $ rank_2020               : int  282 455 332 NA 227 32 33 NA 68 31 ...\n $ differential            : int  -182 -241 -277 -195 -177 469 468 -80 433 -19 ...\n $ release_year            : int  1955 1955 1956 1956 1957 2016 2006 1957 1985 1959 ...\n $ genre                   : chr  \"Big Band/Jazz\" \"Rock n' Roll/Rhythm & Blues\" \"Rock n' Roll/Rhythm & Blues\" \"Big Band/Jazz\" ...\n $ type                    : chr  \"Studio\" \"Studio\" \"Studio\" \"Studio\" ...\n $ weeks_on_billboard      : int  14 NA 100 NA 5 87 173 NA 27 NA ...\n $ peak_billboard_position : int  2 201 1 2 13 1 2 201 30 201 ...\n $ spotify_popularity      : int  48 50 58 62 64 73 67 47 75 52 ...\n $ spotify_url             : chr  \"spotify:album:3GmwKB1tgPZgXeRJZSm9WX\" \"spotify:album:1cbtDEwxCjMhglb49OgNBR\" \"spotify:album:7GXP5OhYyPVLmcVfO9Iqin\" \"spotify:album:4kca7vXd1Wo5GE2DMafvMc\" ...\n $ artist_member_count     : int  1 1 1 1 1 1 1 4 1 1 ...\n $ artist_gender           : chr  \"Male\" \"Male\" \"Male\" \"Male\" ...\n $ artist_birth_year_sum   : int  1915 1928 1935 1915 1932 1981 1983 7752 1958 1926 ...\n $ debut_album_release_year: int  1946 1955 1956 1946 1957 2003 2003 1957 1978 1951 ...\n $ ave_age_at_top_500      : num  40 27 21 41 25 35 23 19 27 33 ...\n $ years_between           : int  9 0 0 10 0 13 3 0 7 8 ...\n $ album_id                : chr  \"3GmwKB1tgPZgXeRJZSm9WX\" \"1cbtDEwxCjMhglb49OgNBR\" \"7GXP5OhYyPVLmcVfO9Iqin\" \"4kca7vXd1Wo5GE2DMafvMc\" ...\n - attr(*, \".internal.selfref\")=&lt;externalptr&gt;"
  },
  {
    "objectID": "material.html#the-syntax",
    "href": "material.html#the-syntax",
    "title": "Introduction to data.table",
    "section": "The syntax",
    "text": "The syntax\nThe general data.table syntax looks like this:\n \n\nDT[i, j, by]\n\n\nWhere DT is a data.table object, the i argument is used for filtering and joining operations, the j argument can summarise and transform, and the by argument defines the groups to which to apply these operations.\nYou can read the syntax as “In these rows, do this, grouped by that”. It is very concise but easy to read (sometimes).\nLet’s start operating over i, meaning over the rows of the table."
  },
  {
    "objectID": "material.html#subset-rows-in-i",
    "href": "material.html#subset-rows-in-i",
    "title": "Introduction to data.table",
    "section": "Subset rows in i",
    "text": "Subset rows in i\nWhich is the number one album in the 2003 ranking? We need to filter our dataset to show only rows where rank_2003 is 1:\n\nrolling_stone[rank_2003 == 1]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsort_name\nclean_name\nalbum\nrank_2003\nrank_2012\nrank_2020\ndifferential\nrelease_year\ngenre\ntype\nweeks_on_billboard\npeak_billboard_position\nspotify_popularity\nspotify_url\nartist_member_count\nartist_gender\nartist_birth_year_sum\ndebut_album_release_year\nave_age_at_top_500\nyears_between\nalbum_id\n\n\n\n\nBeatles\nThe Beatles\nSgt. Pepper’s Lonely Hearts Club Band\n1\n1\n24\n-23\n1967\n\nStudio\n233\n1\n71\nspotify:album:6QaVfG1pHYl1z15ZxkvVDW\n4\nMale\n7765\n1963\n25.75\n4\n6QaVfG1pHYl1z15ZxkvVDW\n\n\n\n\n\nThis is similar to how we’d use a regular data.frame:\n\nrolling_stone[rolling_stone$rank_2003 == 1]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsort_name\nclean_name\nalbum\nrank_2003\nrank_2012\nrank_2020\ndifferential\nrelease_year\ngenre\ntype\nweeks_on_billboard\npeak_billboard_position\nspotify_popularity\nspotify_url\nartist_member_count\nartist_gender\nartist_birth_year_sum\ndebut_album_release_year\nave_age_at_top_500\nyears_between\nalbum_id\n\n\n\n\nBeatles\nThe Beatles\nSgt. Pepper’s Lonely Hearts Club Band\n1\n1\n24\n-23\n1967\n\nStudio\n233\n1\n71\nspotify:album:6QaVfG1pHYl1z15ZxkvVDW\n4\nMale\n7765\n1963\n25.75\n4\n6QaVfG1pHYl1z15ZxkvVDW\n\n\n\n\n\n\ndata.tables are data.frames\nNotice that we can use data.frame syntax on a data.table and it will work just fine in most cases.\n\nBut because all expressions in i are evaluated in the context of the data.table, we don’t need to type the name of the data.frame again. This becomes even more convenient with longer expressions. For example, which are the female bands with more than 3 members?\n\nrolling_stone[artist_gender == \"Female\" & artist_member_count &gt; 3]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsort_name\nclean_name\nalbum\nrank_2003\nrank_2012\nrank_2020\ndifferential\nrelease_year\ngenre\ntype\nweeks_on_billboard\npeak_billboard_position\nspotify_popularity\nspotify_url\nartist_member_count\nartist_gender\nartist_birth_year_sum\ndebut_album_release_year\nave_age_at_top_500\nyears_between\nalbum_id\n\n\n\n\nDestiny’s Child\nDestiny’s Child\nThe Writing’s On the Wall\nNA\nNA\n291\n210\n1999\n\nStudio\n99\n5\n73\nspotify:album:283NWqNsCA9GwVHrJk59CG\n4\nFemale\n7924\n1998\n18.0\n1\n283NWqNsCA9GwVHrJk59CG\n\n\nRaincoats\nThe Raincoats\nThe Raincoats\nNA\nNA\n398\n103\n1979\nPunk/Post-Punk/New Wave/Power Pop\nStudio\nNA\n201\n39\nspotify:album:190Tx9jPHndq0qUlq79BJJ\n4\nFemale\n7814\n1979\n25.5\n0\n190Tx9jPHndq0qUlq79BJJ\n\n\nGo Gos\nThe Go-Go’s\nBeauty and the Beat\n413\n414\n400\n13\n1981\nPunk/Post-Punk/New Wave/Power Pop\nStudio\n72\n1\n56\nspotify:album:1L4HE00En7eNK74voVZums\n5\nFemale\n9785\n1981\n24.0\n0\n1L4HE00En7eNK74voVZums\n\n\nRoss, Diana & the Supremes\nThe Supremes\nAnthology\n431\n423\n452\n-21\n2001\nSoul/Gospel/R&B\nGreatest Hits\nNA\n201\nNA\n\n5\nFemale\n9713\n1962\n58.4\n39\nNOS121\n\n\n\n\n\nIt is also possible to order de rows by any of the columns.\n\nrolling_stone[order(rank_2003)] |&gt; \n  head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsort_name\nclean_name\nalbum\nrank_2003\nrank_2012\nrank_2020\ndifferential\nrelease_year\ngenre\ntype\nweeks_on_billboard\npeak_billboard_position\nspotify_popularity\nspotify_url\nartist_member_count\nartist_gender\nartist_birth_year_sum\ndebut_album_release_year\nave_age_at_top_500\nyears_between\nalbum_id\n\n\n\n\nBeatles\nThe Beatles\nSgt. Pepper’s Lonely Hearts Club Band\n1\n1\n24\n-23\n1967\n\nStudio\n233\n1\n71\nspotify:album:6QaVfG1pHYl1z15ZxkvVDW\n4\nMale\n7765\n1963\n25.75000\n4\n6QaVfG1pHYl1z15ZxkvVDW\n\n\nBeach Boys\nThe Beach Boys\nPet Sounds\n2\n2\n2\n0\n1966\n\nStudio\n40\n10\n62\nspotify:album:2CNEkSE8TADXRT2AzcEt1b\n6\nMale\n11657\n1962\n23.16667\n4\n2CNEkSE8TADXRT2AzcEt1b\n\n\nBeatles\nThe Beatles\nRevolver\n3\n3\n11\n-8\n1966\n\nStudio\n94\n1\n73\nspotify:album:3PRoXYsngSwjEQWR5PsHWR\n4\nMale\n7765\n1963\n24.75000\n3\n3PRoXYsngSwjEQWR5PsHWR\n\n\nDylan, Bob\nBob Dylan\nHighway 61 Revisited\n4\n4\n18\n-14\n1965\nCountry/Folk/Country Rock/Folk Rock\nStudio\n47\n3\n64\nspotify:album:6YabPKtZAjxwyWbuO9p4ZD\n1\nMale\n1941\n1962\n24.00000\n3\n6YabPKtZAjxwyWbuO9p4ZD\n\n\nBeatles\nThe Beatles\nRubber Soul\n5\n5\n35\n-30\n1965\n\nStudio\n70\n1\n76\nspotify:album:50o7kf2wLwVmOTVYJOTplm\n4\nMale\n7765\n1963\n23.75000\n2\n50o7kf2wLwVmOTVYJOTplm\n\n\nGaye, Marvin\nMarvin Gaye\nWhat’s Going On\n6\n6\n1\n5\n1971\nSoul/Gospel/R&B\nStudio\n48\n6\n68\nspotify:album:2v6ANhWhZBUKkg6pJJBs3B\n1\nMale\n1939\n1961\n32.00000\n10\n2v6ANhWhZBUKkg6pJJBs3B\n\n\n\n\n\n\nFilter some rows!\n\nIs your favourite band/artist listed in the data (column sort_name or clean_name)?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[clean_name == \"ABBA\"]\n\n\nWho are the “30 under 30” in 2020? That is, bands with an average age under 30 years (column ave_age_at_top_500) that are in the top 30 in 2020 (rank_2020).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[ave_age_at_top_500 &lt; 30 & rank_2020 &lt; 30]"
  },
  {
    "objectID": "material.html#operating-with-columns-in-j",
    "href": "material.html#operating-with-columns-in-j",
    "title": "Introduction to data.table",
    "section": "Operating with column(s) in j",
    "text": "Operating with column(s) in j\nFiltering and ordering is fun an all, but we need to operate on the columns. Just for fun, what is the mean ranking in 2003?\n\nrolling_stone[, mean(rank_2003, na.rm = TRUE)]\n\n[1] 250.504\n\n\n\nData.table is not type-stable\nNotice that the result of the last expression is a single numeric vector and not a data.table. Operations in j will return a data.table if the result of the expression is a list or a data.table, and other objects if the result is a single object of a different type.\n\nNow, the mean of the numbers 1 through 500 is 250.5, so this results tells us that something strange is going on. Some ranking seems to be missing. How many unique elements do we have? The uniqueN() function is from data.table and is a more efficient version of doing length(unique(rank_2003)).\n\nrolling_stone[, uniqueN(rank_2003, na.rm = TRUE)]\n\n[1] 498\n\n\nHuh. We seem to be missing two rankings?\n\nYour turn\n\nAre more popular albums on Spotify (column spotify_popularity) higher in the 2003 ranking (column rank_2003)? Compute the correlation between the two columns (hint: there are missing values, so you will need to use use = \"complete.obs\").\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, cor(spotify_popularity, rank_2003, use = \"complete.obs\")]\n\n\nWhich rankings are missing in the database?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, which(!(1:500 %in% rank_2003))]\n\n\n\n\nIt’s probably more interesting to calculate the mean rank by genre. Let’s first compute the mean of just one genre.\n\nrolling_stone[genre == \"Electronic\", mean(rank_2003, na.rm = TRUE)]\n\n[1] 376.4286\n\n\n\ndata.table is very efficient at subsetting rows and doing calculations over columns. For this expression:\nrolling_stone[genre == \"Electronic\", mean(rank_2003, na.rm = TRUE)]\ndata.table:\n\nfinds the row indices that match genre == \"Electronic\". It does not subset over the entire table.\nas j uses only one column to compute the mean, data.table subsets only that column and computes the mean.\n\ndata.table can see all three components of the query (i, j and by) and optimise it altogether before evaluation, not each separately.\n\nThere are a lot of genres, so it wouldn’t be too convenient to write one line for each one. It’s much better to group rows by genre using by:\n\nrolling_stone[, mean(rank_2003, na.rm = TRUE), by = genre]\n\n\n\n\ngenre\nV1\n\n\n\n\nBig Band/Jazz\n197.4000\n\n\nRock n’ Roll/Rhythm & Blues\n169.3000\n\n\n\n243.4080\n\n\nSoul/Gospel/R&B\n226.2667\n\n\nHip-Hop/Rap\n297.5000\n\n\nBlues/Blues Rock\n233.2667\n\n\nCountry/Folk/Country Rock/Folk Rock\n207.3611\n\n\nIndie/Alternative Rock\n299.9143\n\n\nPunk/Post-Punk/New Wave/Power Pop\n293.1690\n\n\nElectronic\n376.4286\n\n\nFunk/Disco\n185.7333\n\n\nLatin\n260.0000\n\n\nHard Rock/Metal\n246.2400\n\n\nSinger-Songwriter/Heartland Rock\n275.9231\n\n\nBlues/Blues ROck\n122.0000\n\n\nReggae\n190.8571\n\n\nAfrobeat\nNaN\n\n\n\n\n\nWhen doing stuff with by, the result is always a data.table with the columns used to define the groups and columns to store the results. If we don’t give it any names, data.table assigns the defaults V1, V2, etc. This is fine for quick one-liners, but for regular code it’s much better to name the results. We do this by returning a named list:\n\nrolling_stone[, list(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre]\n\n\n\n\ngenre\nmean_rank\n\n\n\n\nBig Band/Jazz\n197.4000\n\n\nRock n’ Roll/Rhythm & Blues\n169.3000\n\n\n\n243.4080\n\n\nSoul/Gospel/R&B\n226.2667\n\n\nHip-Hop/Rap\n297.5000\n\n\nBlues/Blues Rock\n233.2667\n\n\nCountry/Folk/Country Rock/Folk Rock\n207.3611\n\n\nIndie/Alternative Rock\n299.9143\n\n\nPunk/Post-Punk/New Wave/Power Pop\n293.1690\n\n\nElectronic\n376.4286\n\n\nFunk/Disco\n185.7333\n\n\nLatin\n260.0000\n\n\nHard Rock/Metal\n246.2400\n\n\nSinger-Songwriter/Heartland Rock\n275.9231\n\n\nBlues/Blues ROck\n122.0000\n\n\nReggae\n190.8571\n\n\nAfrobeat\nNaN\n\n\n\n\n\nThis idiom is so common that data.table allows us to use . as an alias for list, so most of the time you’d see something like this:\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre]\n\n\n\n\ngenre\nmean_rank\n\n\n\n\nBig Band/Jazz\n197.4000\n\n\nRock n’ Roll/Rhythm & Blues\n169.3000\n\n\n\n243.4080\n\n\nSoul/Gospel/R&B\n226.2667\n\n\nHip-Hop/Rap\n297.5000\n\n\nBlues/Blues Rock\n233.2667\n\n\nCountry/Folk/Country Rock/Folk Rock\n207.3611\n\n\nIndie/Alternative Rock\n299.9143\n\n\nPunk/Post-Punk/New Wave/Power Pop\n293.1690\n\n\nElectronic\n376.4286\n\n\nFunk/Disco\n185.7333\n\n\nLatin\n260.0000\n\n\nHard Rock/Metal\n246.2400\n\n\nSinger-Songwriter/Heartland Rock\n275.9231\n\n\nBlues/Blues ROck\n122.0000\n\n\nReggae\n190.8571\n\n\nAfrobeat\nNaN\n\n\n\n\n\nAs long as j-expression returns a list, each element of the list will be converted to a column in the resulting data.table. This allows us to return more than one summary expression. What is the mean rank and number of bands included in the rank per genre?\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE),\n                  N = sum(!is.na(rank_2003))), \n              by = genre]\n\n\n\n\ngenre\nmean_rank\nN\n\n\n\n\nBig Band/Jazz\n197.4000\n10\n\n\nRock n’ Roll/Rhythm & Blues\n169.3000\n10\n\n\n\n243.4080\n125\n\n\nSoul/Gospel/R&B\n226.2667\n45\n\n\nHip-Hop/Rap\n297.5000\n26\n\n\nBlues/Blues Rock\n233.2667\n60\n\n\nCountry/Folk/Country Rock/Folk Rock\n207.3611\n36\n\n\nIndie/Alternative Rock\n299.9143\n35\n\n\nPunk/Post-Punk/New Wave/Power Pop\n293.1690\n71\n\n\nElectronic\n376.4286\n7\n\n\nFunk/Disco\n185.7333\n15\n\n\nLatin\n260.0000\n1\n\n\nHard Rock/Metal\n246.2400\n25\n\n\nSinger-Songwriter/Heartland Rock\n275.9231\n26\n\n\nBlues/Blues ROck\n122.0000\n1\n\n\nReggae\n190.8571\n7\n\n\nAfrobeat\nNaN\n0\n\n\n\n\n\nSome of the genres are relatively highly rated, but have very few examples included.\n\nYou can select only some columns using the same syntax but without applying any summary function. To return a data.table with just the columns sort_name and rank_2003 you’d do:\nrolling_stone[, .(sort_name, rank_2003)]\n\nYou might’ve noticed that “Blues/Blues Rock” also appears as “Blues/Blues ROck”. Someone made a typo! We need to modify the genre column to fix that mistake. One way would be to turn all genres to all lower case and forget about cases altogether.\n\nrolling_stone[, genre := tolower(genre)]\n\nThis operator := is called “walrus”. It can be used to update existing columns (like we just did) or to create new ones. It is possible also to delete columns with DT[, variable := NULL].\nNotice that we didn’t get any output and we didn’t assigned the result. But rolling_stone is modified anyway:\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre]\n\n\n\n\ngenre\nmean_rank\n\n\n\n\nbig band/jazz\n197.4000\n\n\nrock n’ roll/rhythm & blues\n169.3000\n\n\n\n243.4080\n\n\nsoul/gospel/r&b\n226.2667\n\n\nhip-hop/rap\n297.5000\n\n\nblues/blues rock\n231.4426\n\n\ncountry/folk/country rock/folk rock\n207.3611\n\n\nindie/alternative rock\n299.9143\n\n\npunk/post-punk/new wave/power pop\n293.1690\n\n\nelectronic\n376.4286\n\n\nfunk/disco\n185.7333\n\n\nlatin\n260.0000\n\n\nhard rock/metal\n246.2400\n\n\nsinger-songwriter/heartland rock\n275.9231\n\n\nreggae\n190.8571\n\n\nafrobeat\nNaN\n\n\n\n\n\nThe := operator modifies columns by reference, so the rolling_stone variable is modified in place instead of making a copy. This makes it very efficient, but potentially surprising!\n\nYour turn\n\nHow may bands in the Latin genre (column genre) appeared in the raking of 2020?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[genre == \"latin\", sum(!is.na(rank_2020))]\n\n\nHow many male, female or mixed-gender (column artist_gender) bands were included in the 2020 ranking (column rank_2020)?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, sum(!is.na(rank_2020)), by = artist_gender]\n\n\nAdd a column with the average of the birth year of each band (columns artist_birth_year_sum and artist_member_count are relevant)?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, artist_birth_year_mean := artist_birth_year_sum/artist_member_count]\n\n\nAdd a column with the average ranking of each album (columns rank_2003, rank_2012 and rank_2020 and album_id).\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, mean_raking := mean(c(rank_2003, rank_2012, rank_2020), na.rm = TRUE), by = album_id]"
  },
  {
    "objectID": "material.html#putting-it-all-together",
    "href": "material.html#putting-it-all-together",
    "title": "Introduction to data.table",
    "section": "Putting it all together",
    "text": "Putting it all together\nUp to now we made one operation at a time but it would be useful to chain operations (like you would do with dplyr for example). Let’s say we want to order genres by their mean ranking in 2003.\nWe can chain operations with data.table by continuing to use [:\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre][order(mean_rank)]\n\n\n\n\ngenre\nmean_rank\n\n\n\n\nrock n’ roll/rhythm & blues\n169.3000\n\n\nfunk/disco\n185.7333\n\n\nreggae\n190.8571\n\n\nbig band/jazz\n197.4000\n\n\ncountry/folk/country rock/folk rock\n207.3611\n\n\nsoul/gospel/r&b\n226.2667\n\n\nblues/blues rock\n231.4426\n\n\n\n243.4080\n\n\nhard rock/metal\n246.2400\n\n\nlatin\n260.0000\n\n\nsinger-songwriter/heartland rock\n275.9231\n\n\npunk/post-punk/new wave/power pop\n293.1690\n\n\nhip-hop/rap\n297.5000\n\n\nindie/alternative rock\n299.9143\n\n\nelectronic\n376.4286\n\n\nafrobeat\nNaN\n\n\n\n\n\nOr like this for better readability:\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre] |&gt; \n    _[order(mean_rank)]\nThis works because since R 4.3.0, _ is a placeholder for the left-hand side of the pipe.\nThere are other possibilities. You could use the old and wise magrittr pipe %&gt;% along with . as a placeholder.\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE)), by = genre] %&gt;%\n    .[order(mean_rank)]\n\nIt is very important to distinguish between the . as alias for list() an the . as a placeholder within the magrittr pipe.\n\nLet’s get serious about analysing these data. It would be interesting to add the proportion as well as the number of albums in each genre:\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE),\n                  N = sum(!is.na(rank_2003))), by = genre] |&gt; \n  _[, prop := N/sum(N)] |&gt; \n  _[order(-prop)]\n\n\n\n\ngenre\nmean_rank\nN\nprop\n\n\n\n\n\n243.4080\n125\n0.250\n\n\npunk/post-punk/new wave/power pop\n293.1690\n71\n0.142\n\n\nblues/blues rock\n231.4426\n61\n0.122\n\n\nsoul/gospel/r&b\n226.2667\n45\n0.090\n\n\ncountry/folk/country rock/folk rock\n207.3611\n36\n0.072\n\n\nindie/alternative rock\n299.9143\n35\n0.070\n\n\nhip-hop/rap\n297.5000\n26\n0.052\n\n\nsinger-songwriter/heartland rock\n275.9231\n26\n0.052\n\n\nhard rock/metal\n246.2400\n25\n0.050\n\n\nfunk/disco\n185.7333\n15\n0.030\n\n\nbig band/jazz\n197.4000\n10\n0.020\n\n\nrock n’ roll/rhythm & blues\n169.3000\n10\n0.020\n\n\nelectronic\n376.4286\n7\n0.014\n\n\nreggae\n190.8571\n7\n0.014\n\n\nlatin\n260.0000\n1\n0.002\n\n\nafrobeat\nNaN\n0\n0.000\n\n\n\n\n\nA full 25% of bands (125) in the 2003 ranking have no assigned genre. Having a empty label is not ideal, let’s modify the variable.\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE),\n                  N = sum(!is.na(rank_2003))), by = genre] |&gt; \n  _[, prop := N/sum(N)] |&gt; \n  _[, genre := ifelse(genre == \"\", \"unknown genre\", genre)] |&gt; \n  _[order(-prop)] \n\n\n\n\ngenre\nmean_rank\nN\nprop\n\n\n\n\nunknown genre\n243.4080\n125\n0.250\n\n\npunk/post-punk/new wave/power pop\n293.1690\n71\n0.142\n\n\nblues/blues rock\n231.4426\n61\n0.122\n\n\nsoul/gospel/r&b\n226.2667\n45\n0.090\n\n\ncountry/folk/country rock/folk rock\n207.3611\n36\n0.072\n\n\nindie/alternative rock\n299.9143\n35\n0.070\n\n\nhip-hop/rap\n297.5000\n26\n0.052\n\n\nsinger-songwriter/heartland rock\n275.9231\n26\n0.052\n\n\nhard rock/metal\n246.2400\n25\n0.050\n\n\nfunk/disco\n185.7333\n15\n0.030\n\n\nbig band/jazz\n197.4000\n10\n0.020\n\n\nrock n’ roll/rhythm & blues\n169.3000\n10\n0.020\n\n\nelectronic\n376.4286\n7\n0.014\n\n\nreggae\n190.8571\n7\n0.014\n\n\nlatin\n260.0000\n1\n0.002\n\n\nafrobeat\nNaN\n0\n0.000\n\n\n\n\n\nWhen doing lots of column modifications like in the previous lines, it’s more convenient (and sometimes more efficient) to do all the modifications in a single step. For that we can use the let() function, which is like a functional form of the walrus operator that can assign multiple columns at once:\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE),\n                  N = sum(!is.na(rank_2003))), by = genre] |&gt; \n  _[, let(prop = N/sum(N),\n          genre = fifelse(genre == \"\", \"unknown genre\", genre))] |&gt; \n  _[order(-prop)] \n\n\n\n\ngenre\nmean_rank\nN\nprop\n\n\n\n\nunknown genre\n243.4080\n125\n0.250\n\n\npunk/post-punk/new wave/power pop\n293.1690\n71\n0.142\n\n\nblues/blues rock\n231.4426\n61\n0.122\n\n\nsoul/gospel/r&b\n226.2667\n45\n0.090\n\n\ncountry/folk/country rock/folk rock\n207.3611\n36\n0.072\n\n\nindie/alternative rock\n299.9143\n35\n0.070\n\n\nhip-hop/rap\n297.5000\n26\n0.052\n\n\nsinger-songwriter/heartland rock\n275.9231\n26\n0.052\n\n\nhard rock/metal\n246.2400\n25\n0.050\n\n\nfunk/disco\n185.7333\n15\n0.030\n\n\nbig band/jazz\n197.4000\n10\n0.020\n\n\nrock n’ roll/rhythm & blues\n169.3000\n10\n0.020\n\n\nelectronic\n376.4286\n7\n0.014\n\n\nreggae\n190.8571\n7\n0.014\n\n\nlatin\n260.0000\n1\n0.002\n\n\nafrobeat\nNaN\n0\n0.000\n\n\n\n\n\n\nYou will probably find examples where a quoted walrus\":=\" is used instead of the function let(). This is a functional form of the walrus operator that allows you to operate over more that one column at the same time.\n\nLooking at numbers in a table is not always enough. Let’s plot the results.\n\nlibrary(ggplot2) #Or any another package to make plots\n\nrolling_stone[, .(mean_rank = mean(rank_2003, na.rm = TRUE),\n                  N = sum(!is.na(rank_2003))), by = genre] |&gt; \n  _[, let(prop = N/sum(N),\n          genre = ifelse(genre == \"\", \"unknown genre\", genre))] |&gt; \n  _[order(-prop)] |&gt; \n  _[, genre := forcats::fct_reorder(genre, prop)] |&gt; \n  ggplot(aes(prop, genre)) +\n  geom_col()\n\n\n\n\n\n\n\n\nThat’s right, you can pipe in a plot after doing the calculations.\n\nYour turn\n\nAre bands (artists with artist_member_count greater than 1) more successful than solo artists?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, is_band := artist_member_count &gt; 1] |&gt;\n  _[, .(mean_rank_2003 = mean(rank_2003, na.rm = TRUE),\n        mean_rank_2012 = mean(rank_2012, na.rm = TRUE),\n        mean_rank_2020 = mean(rank_2020, na.rm = TRUE)), \n    by = is_band]\n\n# Notice that due to reference semantics, this operation adds the \n# is_band column to the data.table. You can avoid this by using \n# an expression in the by argument.\nrolling_stone |&gt; \n  _[, .(mean_rank_2003 = mean(rank_2003, na.rm = TRUE),\n        mean_rank_2012 = mean(rank_2012, na.rm = TRUE),\n        mean_rank_2020 = mean(rank_2020, na.rm = TRUE)), \n    by = .(is_band = artist_member_count &gt; 1)]\n\n\nWhat is the proportion of albums recorded in a Studio and their mean position in 2020?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, .(mean_rank_2020 = mean(rank_2020, na.rm = TRUE),\n                  N = sum(!is.na(rank_2020))), by = type] |&gt; \n  _[, prop := N/sum(N)]\n\n\nWhat is the mean number of years between an artist debut album and the release of their first top 500 album (see the column years_between) for each genre?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone[, .(mean_years = mean(years_between, na.rm = TRUE), .N),\n                by = genre] |&gt; \n  _[order(mean_years)]"
  },
  {
    "objectID": "material.html#special-symbols",
    "href": "material.html#special-symbols",
    "title": "Introduction to data.table",
    "section": "Special symbols",
    "text": "Special symbols\ndata.table has special symbols that provide extra functionality. We are going to only mention .N , which counts the number of rows in the group and it is particularly useful when used along with by.How many albums per year were included in the 2003 ranking? To answer this question we can first filter only albums that were included in the 2003 ranking and then count the number of rows per release_year?\n\nrolling_stone[!is.na(rank_2003)] |&gt; \n  _[, .N, by = release_year] \n\n\n\n\nrelease_year\nN\n\n\n\n\n1955\n2\n\n\n1956\n2\n\n\n1957\n2\n\n\n1959\n5\n\n\n1960\n3\n\n\n1961\n2\n\n\n1962\n2\n\n\n1963\n5\n\n\n1964\n5\n\n\n1965\n14\n\n\n1966\n13\n\n\n1967\n23\n\n\n1968\n21\n\n\n1969\n23\n\n\n1970\n29\n\n\n1971\n21\n\n\n1972\n24\n\n\n1973\n23\n\n\n1974\n16\n\n\n1975\n19\n\n\n1976\n12\n\n\n1977\n18\n\n\n1978\n16\n\n\n1979\n14\n\n\n1980\n9\n\n\n1981\n6\n\n\n1982\n7\n\n\n1983\n7\n\n\n1984\n10\n\n\n1985\n10\n\n\n1986\n8\n\n\n1987\n13\n\n\n1988\n7\n\n\n1989\n9\n\n\n1990\n5\n\n\n1991\n14\n\n\n1992\n6\n\n\n1993\n6\n\n\n1994\n16\n\n\n1995\n8\n\n\n1996\n3\n\n\n1997\n6\n\n\n1998\n8\n\n\n1999\n6\n\n\n2000\n7\n\n\n2001\n7\n\n\n2002\n6\n\n\n2003\n2\n\n\n\n\n\nWhen using the .N symbol, the name of the result is automatically named “N”. Let’s plot that:\n\nrolling_stone[!is.na(rank_2003)] |&gt; \n  _[, .N, by = release_year] |&gt; \n  ggplot(aes(release_year, N)) +\n  geom_col()\n\n\n\n\n\n\n\n\nInterestingly, the majority of the albums in the raking of 2003 where released between the mid 60s and late 70s. Was music better at that time? Or maybe this is a reflection of the people compiling the ranking."
  },
  {
    "objectID": "material.html#reshaping-data",
    "href": "material.html#reshaping-data",
    "title": "Introduction to data.table",
    "section": "Reshaping data",
    "text": "Reshaping data\nDo all rankings have the same album make-up in terms of year of release? We can count the number of non-NA values for each ranking by release year:\n\nrolling_stone[, .(N_2003 = sum(!is.na(rank_2003)),\n                  N_2012 = sum(!is.na(rank_2012)),\n                  N_2020 = sum(!is.na(rank_2020))), by = release_year] |&gt; \n  head()\n\n\n\n\nrelease_year\nN_2003\nN_2012\nN_2020\n\n\n\n\n1955\n2\n2\n2\n\n\n1956\n2\n2\n1\n\n\n1957\n2\n2\n1\n\n\n2016\n0\n0\n5\n\n\n2006\n0\n3\n4\n\n\n1985\n10\n11\n7\n\n\n\n\n\nThis is very tedious, error-prone and makes plotting the result more difficult. Every time you are applying the same operation to multiple columns it is very likely that you’d be better off reshaping your data. In this case, we would like to have a single column with the ranking position and another column that identifies which year’s ranking it is. So, lets melt the table.\n\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\"), \n       measure.vars = c(\"rank_2003\", \"rank_2012\", \"rank_2020\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") |&gt; \n  head()\n\n\n\n\nrelease_year\nalbum_id\nrank_year\nrank\n\n\n\n\n1955\n3GmwKB1tgPZgXeRJZSm9WX\nrank_2003\n100\n\n\n1955\n1cbtDEwxCjMhglb49OgNBR\nrank_2003\n214\n\n\n1956\n7GXP5OhYyPVLmcVfO9Iqin\nrank_2003\n55\n\n\n1956\n4kca7vXd1Wo5GE2DMafvMc\nrank_2003\n306\n\n\n1957\n18tV6PLXYvVjsdOVk0S7M8\nrank_2003\n50\n\n\n2016\n7dK54iZuOxXFarGhXwEXfF\nrank_2003\nNA\n\n\n\n\n\nIt is important to identify the key or id variables (id.vars argument) associated to the observation, the albums. In this case we have release_year and album_id. The measure variables (measure.vars argument) are the variables we want to reshape. By default, the new variables are variable and value but we changed those names using the variable.name and value.name arguments.\n\nWhen you have a lot of columns that go into measure.vars a nd that are named consistently, you can use pattern-based column marching using regular expressions and the patterns() function like here.\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\"), \n       measure.vars = patterns(\"^rank\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") \n\nWe can compute the album proportion again. But now we need to group by two variables: the year of release and the raking year. The by argument can also accepts a list so we’ll use the .() alias.\n\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\"), \n       measure.vars = c(\"rank_2003\", \"rank_2012\", \"rank_2020\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") |&gt; \n  _[!is.na(rank)] |&gt; \n  _[, .N, by = .(release_year, rank_year)] |&gt; \n  head()\n\n\n\n\nrelease_year\nrank_year\nN\n\n\n\n\n1955\nrank_2003\n2\n\n\n1956\nrank_2003\n2\n\n\n1957\nrank_2003\n2\n\n\n1959\nrank_2003\n5\n\n\n1960\nrank_2003\n3\n\n\n1961\nrank_2003\n2\n\n\n\n\n\nLet’s plot the results again.\n\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\"), \n       measure.vars = c(\"rank_2003\", \"rank_2012\", \"rank_2020\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") |&gt; \n  _[!is.na(rank)] |&gt; \n  _[, .N, by = .(release_year, rank_year)] |&gt;\n  ggplot(aes(release_year, N)) +\n  geom_line(aes(color = rank_year))\n\n\n\n\n\n\n\n\nIt looks like the albums released around 1970 were and still are the most popular.\n\nYour turn again!\n\nWhat is the mean rank on each ranking year for gender?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\", \"artist_gender\"), \n       measure.vars = c(\"rank_2003\", \"rank_2012\", \"rank_2020\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") |&gt; \n  _[, .(mean_rank = mean(rank, na.rm = TRUE)), \n    by = .(rank_year, artist_gender)]\n\n\n\n\nThe list has different type of albums, some are Studio albums, some are compilations, etc.\n\nrolling_stone[, unique(type)]\n\n[1] \"Studio\"        \"Compilation\"   \"Live\"          \"Greatest Hits\"\n[5] \"Soundtrack\"   \n\n\nHas the distribution of types of album changed over the decades? Let’s focus on the proportion of Compilation albums compared with the sum of Compilation and Studio albums and the 2003 ranking. First, we can compute the number of albums included in the ranking by type and by decade.\n\n(n_type_decade &lt;- rolling_stone |&gt; \n  _[, .(N = sum(!is.na(rank_2003))), \n    by = .(decade = floor(release_year / 10) * 10, type)])\n\n\n\n\ndecade\ntype\nN\n\n\n\n\n1950\nStudio\n10\n\n\n2010\nStudio\n0\n\n\n2000\nStudio\n16\n\n\n1980\nStudio\n78\n\n\n1990\nStudio\n58\n\n\n1950\nCompilation\n1\n\n\n1960\nStudio\n94\n\n\n1970\nStudio\n171\n\n\n1960\nLive\n8\n\n\n1970\nLive\n5\n\n\n1960\nCompilation\n6\n\n\n1960\nGreatest Hits\n3\n\n\n1970\nCompilation\n8\n\n\n1970\nGreatest Hits\n5\n\n\n1970\nSoundtrack\n3\n\n\n1990\nCompilation\n13\n\n\n2000\nCompilation\n1\n\n\n1980\nCompilation\n3\n\n\n1980\nGreatest Hits\n3\n\n\n1980\nLive\n2\n\n\n1990\nGreatest Hits\n6\n\n\n1990\nLive\n1\n\n\n2000\nGreatest Hits\n5\n\n\n2010\nCompilation\n0\n\n\n\n\n\nTo compute the number of Studio albums divided by the sum of Studio albums and compilations we need each type of album as its own column. We need to reshape our data again! But this time instead of making it longer, we need to make it wider. We can use dcast() for this\n\nn_type_decade |&gt; \n  dcast(decade ~ type, value.var = \"N\") \n\n\n\n\ndecade\nCompilation\nGreatest Hits\nLive\nSoundtrack\nStudio\n\n\n\n\n1950\n1\nNA\nNA\nNA\n10\n\n\n1960\n6\n3\n8\nNA\n94\n\n\n1970\n8\n5\n5\n3\n171\n\n\n1980\n3\n3\n2\nNA\n78\n\n\n1990\n13\n6\n1\nNA\n58\n\n\n2000\n1\n5\nNA\nNA\n16\n\n\n2010\n0\nNA\nNA\nNA\n0\n\n\n\n\n\nThere are a lot of NAs for the combinations that didn’t appear in our long data. We know that in this case, these mean zero albums for that category for that decade. We can replace all NAs with zeroes with the setnafill() function (as the “set” prefix implies, this function modifies by reference).\n\nn_type_decade |&gt; \n  dcast(decade ~ type, value.var = \"N\") |&gt; \n  setnafill(fill = 0) |&gt; \n  head()\n\n\n\n\ndecade\nCompilation\nGreatest Hits\nLive\nSoundtrack\nStudio\n\n\n\n\n1950\n1\n0\n0\n0\n10\n\n\n1960\n6\n3\n8\n0\n94\n\n\n1970\n8\n5\n5\n3\n171\n\n\n1980\n3\n3\n2\n0\n78\n\n\n1990\n13\n6\n1\n0\n58\n\n\n2000\n1\n5\n0\n0\n16\n\n\n\n\n\nWith that, we can now compute and plot the value we want\n\nn_type_decade |&gt; \n  dcast(decade ~ type, value.var = \"N\") |&gt; \n  setnafill(fill = 0) |&gt; \n  _[, ratio := Compilation/(Studio + Compilation)] |&gt; \n  ggplot(aes(decade, ratio)) +\n  geom_line() \n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n\n\n\n\n\nCompilation albums make up less than 10% of the picks, except in the 90s.\n\nYour turn!\n\nWhat is the proportion of Male to Female artists for each decade in the 2003 ranking?\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone |&gt; \n  _[, .(N = sum(!is.na(rank_2003))), \n    by = .(decade = floor(release_year / 10) * 10, artist_gender)] |&gt; \n  dcast(decade ~ artist_gender, value.var = \"N\") |&gt; \n  setnafill(fill = 0) |&gt; \n  _[, ratio := Male / (Male + Female)] |&gt; \n  ggplot(aes(decade, ratio)) +\n  geom_line()\n\n\nHas this changed between the different ranking years? (You need to first melt and then dcast)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nShow one solution\nrolling_stone |&gt; \n  melt(id.vars = c(\"release_year\", \"album_id\", \"artist_gender\"), \n       measure.vars = c(\"rank_2003\", \"rank_2012\", \"rank_2020\"), \n       variable.name = \"rank_year\",\n       value.name = \"rank\") |&gt; \n  _[, .(N = sum(!is.na(rank))),\n    by = .(decade = floor(release_year / 10) * 10, artist_gender, rank_year)] |&gt; \n  dcast(decade + rank_year ~ artist_gender, value.var = \"N\") |&gt; \n  _[, ratio := Male / (Male + Female)] |&gt; \n  ggplot(aes(decade, ratio)) +\n  geom_line(aes(color = rank_year))"
  }
]